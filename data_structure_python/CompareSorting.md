# 목 차

## 1. 대량의 데이터 생성하기

###   1) 데이터의 생성

###   2) 중복 검사 검증

## 2. 정렬

###   1) 정렬의 보증

###   2) 내장함수

###   3) 퀵정렬

###   4) 퀵정렬(비재귀)

###   5) 힙정렬

###   6) 선택정렬

## 3. 결론



# 1. 대량의 데이터 생성하기

대량의 데이터를 생성하는 과정은 대량의 데이터를 생성하는 함수 generate\_data( )와 생성된 데이터의 중복을 검증하는 함수인 validate\_duplication( )으로 구성되어 있다.

### 1) generate\_data( )

- 데이터 구조의 설계
  - 50000개의 데이터는 2차원 리스트로 구성된다. 
  - 한 개인에 대한 데이터를 list의 element로 넣는다. 이후 50000명 분에 대한 데이터를 생성한 후 하나의 data list에 저장한다. 
  - [[id, name, phone\_number], [id, name, phone\_number], …, [id, name, phone\_number]]
  - 이후 이를 return 한다.

- 데이터의 생성
  - 중복이 없는 학번을 생성한 후 이에 대한 무작위 이름과 전화번호를 할당하는 방식으로 이루어진다. 이 때 이름과 전화번호는 중복이 가능하다.

- 학번 : student\_id\_list = random.sample(range(20130000, 20200000), size)
  - random 모듈의 sample 메소드를 활용한다. 
  - 이는 주어진 범위 내에서 비복원 추출을 하는 것으로 20130000 ~ 20219999 사이에서 무작위로 size 만큼 추출하여 student\_id\_list에 저장한다. 
  - 이 때 size를 지정한 것은 main에서 size를 지정하게 함으로써 데이터의 숫자가 변경되었을 때 수정이 용이하도록 하기 위함이다. 
  - 학번이 생성되면 student\_id\_list를 인자로 하는 validate\_duplication을 실행하여 중복을 확인한다.

- 이름 : name = "". join([random.choice(string.ascii\_lowercase) for \_ in range(10)])
  - random 모듈의 choice 메소드를 활용한다. 
  - 이는 주어진 범위 내에서 1개를 선택하는 것으로 string클래스의 ascii\_lowercase에서 소문자 한 개를 선택하도록 한다. 
  - 이와 같은 과정을 list comprehension을 통해 10회 반복하고 하나의 리스트에 넣는다. 
  - 이후 join 메소드를 통해 리스트 내부의 element를 문자열로 합쳐 반환토록 한다.

- 전화번호 : phone\_number = "010" + "".join([str(random.randint(0, 9)) for \_ in range(8)])
  - random 모듈의 randint 메소드를 활용한다. 
  - 이는 주어진 정수범위 내에서 1개를 추출하는 것으로 0~9범위에서 진행한다. 
  - 이름과 동일하게 전화번호 뒷부분에 해당하는 8자리 숫자를 생성한다. 
  - 다만 join 메소드의 인자의 형은 문자형태이므로 타입 캐스팅을 통해 정수형을 문자로 변경한다. 
  - 이렇게 생성된 8자리 숫자와 010을 합친다. 

### 2) validate\_duplication : if len(set(data)) == size

- 구현
  - 중복 요소 존재 검증을 위하여 set을 활용한다.
  - Set은 수학의 집합과 같이 각 요소가 유일한 값을 갖는다.
  - 그러므로 인자로 전달받은 리스트를 set으로 변경하였을 때 중복값이 존재한다면 set의 요소는 줄어들게 된다.
  - 그러므로 set의 길이와 기존에 지정해준 size와 비교하여 중복을 판단한다.

- 시간복잡도
  - 위 과정은 크게 세 단계로 이루어진다.
  - 인자로 받은 data를 set으로 변환 
    - list의 각 요소를 한번씩 순회하며 => O(n) 
    - 이를 set에 추가해주어야 한다. => O(1) 
    - 그러므로 해당 작업의 시간복잡도는 O(n)이다.

  - 변환된 set의 길이 반환 
    - 파이썬에는 이미 set 객체의 길이정보(\_\_len\_\_)이 포함되어 있다. 
    - 그러므로 이 정보에 접근하기만 하면 되므로 O(1)이다.

  - Size와 비교연산
    - 해당 연산은 1회 일어나므로 O(1)이다.

  - **그러므로 중복여부를 파악하는 과정의 시간복잡도는 O(n)이다.**

- 실행결과

  ![image](https://user-images.githubusercontent.com/63644587/116435663-92fbed80-a886-11eb-8c4f-a6de85c68715.png)



# 2. 정렬

### 1) 정렬의 보증(validate\_order(data) : if data[i] > data[i+1])

- 구현
  - 정렬된 list에서 zip을 통해 이름이 존재하는 두번째 열만 추출하여 해당 함수의 인자로 한다.  
  - sorted\_name = list(zip(\*list))[1] => validate\_order(sorted\_name)
  - 정렬의 보증을 위해 인자로 받은 data 전체를 순회한다.
  - 오름차순으로 정렬되어있으므로 현재 항목보다 다음 항목이 더 작게 되면 정렬이 되지 않았음을 의미하므로 이를 알리고 반복문을 탈출한다.
  - 만약 반복문을 마치게되면 정렬이 올바르게 된 것이므로 정렬되었음을 알린다.
- 시간복잡도
  - 위 과정은 크게 두 단계로 이루어진다.
  - 정렬된 list에서 zip을 통해 이름이 존재하는 두번째 열만 추출
    - list의 각 요소를 한번씩 순회하며 => O(n) 
    - 이를 list에 추가해주어야 한다. => O(1) 
    - 그러므로 해당 작업의 시간복잡도는 O(n)이다.

  - Sorted name의 요소를 순회하며 다음 요소와 비교
    - list의 각 요소를 한번씩 순회하되, 정렬이 되지 않은 부분이 있으면 멈춘다 
    => 1~n-1회 => O(n) 
    - 현재 요소와 다음 요소의 값을 가져오는 array access 2회 => O(1)
    - 두 값의 크기를 비교 =>O(1)
    - 그러므로 해당 작업의 시간복잡도는 O(n)이다.

  - **그러므로 정렬여부를 파악하는 과정의 시간복잡도는 O(n)이다.**


### 2) 내장함수

- 시간측정 구현
  - Time 모듈을 활용하여 정렬 직전, 직후의 현재시간을 가져온다.
  - 정렬의 실행시간은 직후의 현재시간 – 직전의 현재시간이다.



- 정렬 구현
  - 파이썬의 내장 정렬함수는 Tim sort를 활용한다. 이는 병합정렬과 삽입정렬을 합한 형태로서 최악의 경우 O(nlogn), 최상의 경우 O(n)를 보장하는 안정적인 정렬 알고리즘이다.
  - Sort 메소드의 경우 리스트에 대해서 원본의 인덱스를 변환하고 none값을 리턴한다.
  - Sorted 메소드의 경우 모든 iterable 객체를 정렬한 후 이를 반환한다. 그러므로 원본의 손상이 없는 Sorted를 활용 한다.
  - 이 때 정렬의 기준이 되는 Key값을 lambda를 통해 이름이 있는 두번째 열로 지정하도록 한다.
  - 반환된 정렬된 list를 새로운 변수에 assign 함으로써 정렬된 값을 따로 유지한다.

- 정렬결과 출력
  - For문을 통해 0에서 size까지 increment를 1000으로 설정하여 해당 인덱스에 해당하는 값을 출력한다. 

- 실행결과

  ![image](https://user-images.githubusercontent.com/63644587/116435928-d8b8b600-a886-11eb-80f8-777c03f225e6.png) ![image](https://user-images.githubusercontent.com/63644587/116435951-df472d80-a886-11eb-997d-0b55e64a7027.png)




### 3) 퀵정렬

- 시간측정 구현
  - 이전과 동일하게 Time 모듈을 활용하여 정렬 직전, 직후의 현재시간을 가져온다.
  - 정렬의 실행시간은 직후의 현재시간 – 직전의 현재시간이다.

- 정렬 구현
  - 원본 데이터를 손상시키면 안 되므로 새로운 리스트를 구성하여야 한다. 이 때 copy메소드나 인덱스 슬라이싱을 활용하게 되면 shallow copy를 하게 되어 각 참조변수가 동일한 원본 리스트를 가리키게 된다. 그러므로 copy 모듈의 deepcopy 메소드를 활용하여 깊은 복사를 진행한다. 
  - 퀵 정렬의 구현은 재귀적으로 피봇값을 기준으로 구획을 나눈 후 sub array들에 대한 퀵정렬을 구현하는 quick\_sort(arr, lo, hi)와 피봇을 기준으로 작은 값과 큰 값으로 나누는 partition(arr, pivot, hi)로 나뉘어진다.
  - quick\_sort(arr, lo, hi)
    - 리스트와 양 끝단의 인덱스를 인자로 입력받아 partiton함수를 통해 구획을 나눈다.
    - 피봇을 기준으로 좌측 리스트와 우측 리스트에 대해 재귀적으로 quick\_sort를 호출한다.
    - 이러한 과정을 lo가 hi보다 커질 때 까지, 즉 더 이상 분리되지 않을 때 까지 수행한다. 
  - Partition(arr,pivot, hi)
    - 피봇을 기준으로 피봇보다 작은 값을 좌측에, 피봇봐 큰 값을 우측에 위치시킨다.
    - 피봇은 첫번째 인덱스로 지정한다.
    - i(피봇 다음 값)이 리스트의 우측 극단까지 진행하면서 피봇보다 큰 값을 찾을 때 까지 증가한다.
    - j(리스트 우측 극단)이 리스트의 좌측 극단까지 진행하면서 피봇보다 작은 값을 찾을 때 까지 감소한다.
    - i와 j가 목표로 하는 값을 찾은 경우 이 둘의 위치를 서로 변경한다.
    - 위와 같은 과정을 j가 i이하값이 될 때 까지, 즉 partition이 완료될 때 까지 반복한다.
    - partition이 완료되었다면 피봇과 피봇보다 작은 구역의 마지막 값(j)의 위치를 변경한다.
    - 결과적으로 피봇을 중심으로 좌측에는 피봇보다 작은 값, 우측에는 피봇보다 큰 값이 위치하게 된다.
    - 피봇의 위치(j)를 반환하여 이후 quick\_sort에서 이를 기준으로 재귀적인 Partition이 가능하도록 한다.

- 정렬결과 출력
  - 이전과 동일하게 For문을 통해 0에서 size까지 increment를 1000으로 설정하여 해당 인덱스에 해당하는 값을 출력한다. 

- 실행결과
  ![image](https://user-images.githubusercontent.com/63644587/116436056-fa19a200-a886-11eb-9e57-fef6d4bdbbc6.png) ![image](https://user-images.githubusercontent.com/63644587/116436076-ff76ec80-a886-11eb-9018-97a33f6b924b.png)


### 4) 퀵정렬 (비재귀)

- 재귀를 활용한 정렬 방식은 재귀의 깊이가 깊어질수록 효율이 떨어지는 한편, 스택 오버플로우가 발생할 염려가 있다.
  - 이에 스택과 반복문을 활용한 buttom up 방식으로 퀵 정렬을 구할 수 있다.
  - 재귀에 의한 오버헤드와 스택을 별도로 운영하며 발생하는 오버헤드를 비교하는 것이 목적이다.
  - 여기서 stack은 list의 append, pop을 활용하지 않고, stack class를 별도 구현하였다.

- 구현
  - 재귀적 호출에 의한 퀵정렬의 quick\_sort 부분을 제외하면 시간 측정, 리스트의 깊은 복사, partition 함수, 정렬결과 출력 등 모든 구현 방식은 이전과 동일하다.

  - quick\_sort\_non\_recursive(arr, lo, hi)
    - 위 함수가 호출되면, stack을 생성하고 리스트의 각 극단을 의미하는 lo와 hi를 push한다.
    - 이후 lo와 hi를 pop하여 partition 함수의 인자로 사용하여 피봇을 기준으로 분할한다.
    - Partition 함수는 피봇을 기준으로 구획이 나뉘어지고, 피봇이 구획 사이에 위치하도록 하며, 마지막으로 그 피봇의 위치를 반환한다.
    - 만약 반환 값 – 1(피봇보다 작은 구역의 가장 큰 인덱스)의 값이 sub array를 포함하여 리스트의 좌극단인 lo보다 크다면 파티셔닝이 가능하다는 뜻이다. 그러므로 lo값과 pivot-1을 스택에 push한다.
    - 반대로 반환 값 +1(피봇보다 큰 구역의 가장 작은 인덱스)의 값이 sub array를 포함하여 리스트의 우극단인 hi보다 크다면 파티셔닝이 가능하다는 뜻이다. 그러므로 hi값과 pivot+1을 스택에 push한다.
    - 위와 같은 과정을 스택이 빌 때 까지(더 분할이 불가능한 경우) 반복한다.

- 실행결과
  ![image](https://user-images.githubusercontent.com/63644587/116436142-1289bc80-a887-11eb-8f78-f9861a6e5814.png) ![image](https://user-images.githubusercontent.com/63644587/116436156-1584ad00-a887-11eb-8578-b99937b2e774.png)



### 5) 힙정렬

- 시간측정 구현
  - Time 모듈을 활용하여 정렬 직전, 직후의 현재시간을 가져온다.
  - 정렬의 실행시간은 직후의 현재시간 – 직전의 현재시간이다.



- 정렬 구현
  - 원본 데이터를 손상시키면 안 되므로 새로운 리스트를 구성하여야 한다. 이 때 copy메소드나 인덱스 슬라이싱을 활용하게 되면 shallow copy를 하게 되어 각 참조변수가 동일한 원본 리스트를 가리키게 된다. 그러므로 copy 모듈의 deepcopy 메소드를 활용하여 깊은 복사를 진행한다. 


  - 힙정렬의 구현은 크게 두 부분으로 이루어진다. 
    - 첫째, 리스트의 데이터를 기반으로 초기 max heap을 구성한다. 이는 트리의 마지막 부모노드에 해당하는 부분부터 상향하며 adjust가 이루어진다.
    - 둘째, 가장 큰 수를 제거한 후 다시 max heap을 구성한다. 이는 초기 Max heap의 가장 큰 수(0번째 인덱스)와 마지막 인덱스를 맞바꾼 후, 최대 인덱스를 줄임으로써 사실상 가장 큰 수를 제거한 것과 같은 효과를 낸다.
    - Max heap의 구성은 adjust 함수를 호출함으로써 이루어진다.

  - Adjust(arr, root\_idx, max\_idx)
    - 부모 노드의 인덱스인 root\_idx를 기반으로 첫번째 자식 노드를 설정한다. 
    - 첫번째 자식 노드의 인덱스는 부모 인덱스 \* 2 + 1이다. 아래 예시와 같이 index 1의 첫번째 자식 노드는 1 \* 2 + 1 = 3이 된다.

      |||<p>(0)</p><p>10</p>||
      | :-: | :-: | :-: | :-: |
      ||/||＼|
      ||<p>(1)</p><p>9</p>||<p>` `(2)</p><p>`  `4</p>|
      |/|<h3>` `＼</h3>|||
      |<p>(3)</p><p>` `8</p>|<p>` `(4)</p><p>9</p>|||


      |Index|0|1|2|3|4|
      | :-: | :-: | :-: | :-: | :-: | :-: |
      |Value|10|9|4|8|7|


    - 동일 층위에 있는 형제 노드끼리 비교를 수행하여 더 큰 것을 부모노드와의 비교 대상으로 삼는다.
    - 형제 노드 중 더 큰 것과 부모 노드를 비교하여 둘 중 큰 수가 위로 올라갈 수 있도록 한다.
    - 만약 부모노드가 더 작은 경우 부모가 아래로 내려와 힙이 깨지므로 재구성이 필요하다. 그러므로 새로 내려온 부분을 부모노드로 삼아 아래에 있는 자식 노드들과 비교를 한다.
    - 이러한 과정을 자식노드가 마지막 인덱스에 다다를 때 까지 반복하며, 만약 비교 후 부모노드가 더 크다면 힙 구성이 완료 되었다는 뜻이므로 반복을 멈춘다. 

- 정렬결과 출력
  - For문을 통해 0에서 size까지 increment를 1000으로 설정하여 해당 인덱스에 해당하는 값을 출력한다. 


- 실행 결과 

  ![image](https://user-images.githubusercontent.com/63644587/116436304-3e0ca700-a887-11eb-9d16-f9844b2fd2f8.png) ![image](https://user-images.githubusercontent.com/63644587/116436322-42d15b00-a887-11eb-9078-10643943b860.png)



### 6) 선택정렬

- 시간측정 구현
  - Time 모듈을 활용하여 정렬 직전, 직후의 현재시간을 가져온다.
  - 정렬의 실행시간은 직후의 현재시간 – 직전의 현재시간이다.



- 정렬 구현
  - 원본 데이터를 손상시키면 안 되므로 새로운 리스트를 구성하여야 한다. 이 때 copy메소드나 인덱스 슬라이싱을 활용하게 되면 shallow copy를 하게 되어 각 참조변수가 동일한 원본 리스트를 가리키게 된다. 그러므로 copy 모듈의 deepcopy 메소드를 활용하여 깊은 복사를 진행한다. 
  - 리스트의 모든 요소에 대해 각 요소보다 가장 작은 값을 찾아 위치를 맞바꾼다.
  - 이를 위해 각 요소의 인덱스인 i를 min값으로 설정하고, min의 값보다 작은 값을 만날 때마다 min을 작은 요소의 인덱스(j)로 바꾼다.
  - 그 결과 최종적으로 j의 값은 정렬되지 않은 값 중 가장 작은 값이다.
  - i와 j의 값을 맞바꾼 후, i를 증가, 위의 작업을 반복하여 정렬된 부분을 늘려나간다. 


- 정렬결과 출력
  - For문을 통해 0에서 size까지 increment를 1000으로 설정하여 해당 인덱스에 해당하는 값을 출력한다.
  
- 실행 결과

  ![image](https://user-images.githubusercontent.com/63644587/116436393-554b9480-a887-11eb-87ab-0ec84aa3ebf4.png) ![image](https://user-images.githubusercontent.com/63644587/116436436-5c72a280-a887-11eb-82b2-782ac9e8e7e1.png)



# 3. 결론


||**내장정렬함수**|**퀵정렬**|**퀵정렬(비재귀)**|**힙정렬**|**선택정렬**|
| :-: | :-: | :-: | :-: | :-: | :-: |
|**중복 검증**|O|O|O|O|O|
|**정렬 검증**|O|O|O|O|O|
|**소요 시간**|0.023|0.280|0.308|0.555|285.118|

- 내장정렬함수
  - 나머지 정렬 방식에 비해 압도적인 시간차이를 보여준다. 이는 파이썬의 Tim sort가 하이브리드 정렬로서, 수행한 방법 중 가장 최적화된 정렬 방식이기 때문이다.
  - 더불어 사용자정의 함수를 선언하는 것이 아니므로 오버헤드가 가장 작기 때문에 매우 빠른 속도를 냈다고 생각했다.

- 퀵정렬과 힙정렬
  - 퀵정렬의 경우 최악의 상황에서 On2이지만, 평균적인 경우에서는 가장 좋은 효율을 보여준다.
  - 힙정렬의 경우 퀵정렬과 동일하게 Onlogn이지만 약 2배가량 속도가 느린 것을 알 수 있다. 그 이유는 max heap을 구성하는 heapify과정에서 퀵정렬에 비해 많은 SWAP이 일어나고, 데이터가 많아질수록 그 양이 커진다. 특히 cache의 hit ratio가 떨어지므로 실질적인 속도는 퀵정렬보다 떨어지게 된다.

- 퀵정렬과 비재귀 퀵정렬
  - 정렬 알고리즘을 최적화하기 위한 방안으로 재귀호출을 감소시키는 방법이 있다. 
  - 이는 스택과 반복문을 활용하여 개선할 수 있다.
  - 그러나 비재귀 퀵정렬의 결과가 근소하지만 더 좋지 않은 것으로 드러났다.
  - 이는 재귀적 호출에 의한 오버헤드보다 스택을 사용자 정의 클래스를 정의하고, push와 pop 작업이 이중적으로 이루어지는 등 기타 오버헤드가 더 컸다고 예상할 수 있다.

- 선택정렬
  - 선택정렬의 결과는 데이터가 많아질수록 알고리즘의 효율성이 중요하다는 사실을 여실히 보여준다.
  - 50000개 데이터 정렬에 약 5분의 시간이 걸렸다. 이는 데이터가 더욱 증가할수록 기하급수적으로 증가할 것이다.















` `PAGE 2


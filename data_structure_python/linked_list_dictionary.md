**목 차**


**1. 사전만들기……………………………………………………………...3**

**1) 연결리스트 구조…………………………………………………………………………….3**

**2) 사전 생성……………………………………………………………………………………..4**

**3) 탐색 및 추가…………………………………………………………………………………4**

**4) 출력 결과……………………………………………………………………………………..5**

**5) 개선 전후 비교……………………………………………………………………………...6**




# **1. 사전 만들기**

## **1) 연결리스트 구조**

- 노드 class
  - 하나의 데이터를 의미하는 노드는 다음과 같은 구조로 이루어져 있다.
  - self.word : 영단어
  - self.meaning : 영단어의 뜻
  - self.next : 다음 노드의 주소

- 연결리스트(Dictionary class)
  - 연결리스트는 단방향으로 구성된 연결리스트를 활용하며 맨 앞 노드를 가리키는 head와 맨 뒤 노드를 가리키는 tail를 운용함과 동시에 노드의 갯수를 의미하는 size 변수를 운용한다.
  - 해당 클래스의 method에 대한 ADT는 다음과 같다.


## **2) 사전 생성**

- 분할된 리스트 생성
  - 사전 초기화 및 탐색의 효율성을 증대하기 위하여 개별 알파벳 별 연결리스트를 선언한다.
  - a~z 까지 총 26개의 Dictionary 클래스를 선언하고, 이에 대한 참조변수들을 index라는 리스트에 넣어 운용한다.

    |a 사전|b 사전|c 사전|d 사전|e 사전|…|z 사전|
    |0|1|2|3|4|…|25|

- 추가할 단어의 리스트 할당
  - txt 파일에서 한줄씩 읽어 split을 통해 단어와 뜻을 분리한다. 만약 뜻이 빈 경우 추가하지 않는다.
  - 추출된 단어의 첫 글자의 아스키코드에서 a를 의미하는 97을 빼어 분할된 리스트에 접근할 수 있는 변수 idx를 계산한다.
  - 각 알파벳별 리스트의 참조변수인 index List의 해당 알파벳 리스트에 접근한다.
  - 예를 들어 apple을 추가한다면 index[0]에 접근하게 된다.

- 단어 추가
  - where\_to\_insert(self, word) 메소드를 호출하여 해당 리스트에서 추가할 단어가 삽입될 위치를 찾는다. 이는 맨 앞 head에서부터 순차적으로 순회하며 더 큰 단어를 만났을 때 해당 위치를 반환한다.
  - 해당 위치에 insert(self, pos, word, meaning)을 호출하여 지정 위치에 단어와 뜻을 삽입한다.

- 분할된 리스트 병합
  - 모든 단어가 알파벳별로 분리되어 저장되었다면 이를 하나로 이어주는 작업을 수행한다.
  - concat(self, list) 메소드를 통해 두 리스트를 연결한다. 이는 앞 리스트의 마지막 노드가 뒤 리스트의 첫번째를 가리키도록 함으로써 이루어진다.
  - 모든 리스트가 하나로 연결되었다면 eng\_dict 인스턴스를 생성하여 이것의 head를 index[0]의 head로, tail을 index[25]의 tail로 지정하고, 통합된 size로 초기화한다.

## **3) 탐색 및 추가**

- 탐색 
  - 입력받은 단어를 target에 저장한다.
  - 사전 초기화와 동일하게 탐색의 효율성을 위하여 해당 단어의 알파벳부터 탐색을 시작한다.
  - 이를 위해 동일하게 ascii코드를 연산하여 idx를 계산하고, 해당 참조변수를 통해 해당 알파벳 리스트의 가장 첫 노드에 접근한다.
  - search(self, target) 메소드를 통해 리스트의 노드를 순회하며 해당 단어를 찾는다.
  - 만약 찾는 단어가 있다면 그 단어의 뜻을 반환하고 없다면 None을 반환한다.
  - 반환 받은 단어의 뜻을 출력한다.

- 추가 
  - 만약 해당하는 단어가 없다면 뜻을 추가하여 리스트에 저장한다. 
  - 이를 위해 이미 ascii코드로 계산된 idx를 기반으로 where\_to\_insert(self, word) 메소드를 호출하여 해당 리스트에서 추가할 단어가 삽입될 위치를 찾는다.
  - 해당 위치에 insert\_new(self, pos, idx, word, meaning)을 호출하여 지정 위치에 단어와 뜻을 삽입한다.
  - 사전 초기화의 Insert와 다른 메소드를 운용하는 이유는, 새로운 메소드없이 운용은 가능하나, 현재 모든 리스트가 병합되었으므로 전체리스트에서 해당 알파벳의 위치로 바로 접근하여 추가하고, 전체 리스트의 size 최신화하기 위함이다.

## **4) 출력 결과**

- 추가된 단어의 정렬 
- 오름차순으로 정렬이 된 것을 확인할 수 있다.
  
  ![image](https://user-images.githubusercontent.com/63644587/117574997-da9e3700-b11a-11eb-84b2-195ae0e5dc69.png)
  
  ![image](https://user-images.githubusercontent.com/63644587/117575001-df62eb00-b11a-11eb-9145-ad95efc5c529.png)



- 단어 검색
- 정상적으로 존재하는 단어에 대한 뜻을 출력한다.

  ![image](https://user-images.githubusercontent.com/63644587/117575010-e984e980-b11a-11eb-8c60-3358395b09c9.png)

- 단어 추가
- 존재하지 않는 단어를 뜻을 입력받아 추가한다.

  ![image](https://user-images.githubusercontent.com/63644587/117575019-f0abf780-b11a-11eb-8076-57044ed49e14.png)

- 새로 추가하는 경우에도 오름차순으로 정렬이 된 것을 확인할 수 있다.

  ![image](https://user-images.githubusercontent.com/63644587/117575024-f73a6f00-b11a-11eb-88c4-e7f89cb79f5d.png)


## **5) 개선 전후 비교**

- 연결리스트의 경우 random access가 불가능하여 이진탐색을 수행할 수 없다. 이에 오로지 선형으로 탐색완료시까지 전체 노드를 순회하여야 하는 단점이 있다. 이는 데이터 양이 많아질수록 소요시간 역시 크게 증가함을 의미한다.

- 이에 실제 우리가 사전에서 단어를 찾을 때 해당 알파벳부터 찾는 것처럼, 알파벳을 기준으로 리스트의 색인을 유지하고, 특정 단어를 삽입 혹은 검색 시 활용하여 바로 접근할 수 있도록 하였다. 

- 이를 테스트하기 위해서 각 노드를 순회하는 횟수를 비교하였다.
  - where\_to\_insert 메소드와 search 메소드에 count 변수를 운용하여 다음 노드로 이동할 때 마다 이를 1씩 추가해주었다. 
  - 이후 해당 메소드의 원래 반환값과 함께 count를 tuple 형태로 반환한다.
  - main 메소드에서는 이러한 결과값을 저장하는 세가지 변수 혹은 자료형을 운용한다.
    - init\_count : 사전 초기화 시 총 순회 횟수를 저장한다.
    - operation\_per\_word[]: 단어 하나가 저장될 때까지의 순회 횟수를 저장한다.
    - search\_count{} : 딕셔너리에 특정 단어를 검색했을 때 순회 횟수를 저장한다.
    - 해당 값을 각 방식이 종료될 때 반환한다.

- validate\_improvement( )
  - 각 방식별로 연산횟수를 반환받아 이를 기반으로 개선이 타당한지 확인한다.
  - 횟수와 함께 그래프, 통계를 통해 타당성을 검증하였다. 

- 연산횟수
  - txt 파일로부터 사전을 만드는 작업에 소요되는 노드 순회 횟수와 특정 단어를 찾았을 때 소요되는 노드 순회 횟수는 다음과 같다.

    ![image](https://user-images.githubusercontent.com/63644587/117575036-0b7e6c00-b11b-11eb-8a41-4cd77a2106b5.png)


- 사전 초기화 작업의 경우 전체를 순회할 때 횟수가 약 6억회에 달하는 반면 개선된 경우에는 3천 5백만회로 약 17배 적은 것을 알 수 있다. 
- 단어 검색의 경우 첫 알파벳, 중간 알파벳, 마지막 알파벳으로 테스트 하였다.
  - a의 경우 둘 다 맨 앞에서 순회하므로 동일하다.
  - 기존 알고리즘에서 m의 경우 알파벳 중간에 해당하므로 전체 데이터의 약 절반만큼, z의 경우 알파벳 마지막에 해당하므로 전체데이터 만큼 순회한다.
  - 그러나 개선된 알고리즘에서는 알파벳의 순서와 관계 없이 해당 알파벳의 첫 노드부터 순회하므로 현저히 개선된 것을 볼 수 있다.
- 그래프 
  - 개별 단어를 추가하는데 소요되는 연산의 횟수를 그래프로 나타내면 다음과 같다.
  - 막대그래프

    ![image](https://user-images.githubusercontent.com/63644587/117575044-176a2e00-b11b-11eb-945d-3f1c46a0da34.png)


  - 선그래프

    ![image](https://user-images.githubusercontent.com/63644587/117575053-1fc26900-b11b-11eb-852d-35a4ba66df13.png)


    - x축은 n번째 단어를 의미하며 y축은 해당 단어의 연산 횟수를 의미한다.
    - 두 방식 모두 추가되는 데이터의 양이 많아질수록 연산의 횟수가 늘어남을 알 수 있다. 
    - 그러나 개선된 알고리즘의 경우 단어들이 알파벳별로 균일하게 분포하고 있다면 연산의 횟수가 크게 절감됨을 알 수 있다. 다만 모든 데이터가 특정 알파벳에 몰려있다면 이것의 효과는 크지 않으며 최악의 경우 개선전후가 동일하게 된다.

  - 히스토그램

    ![image](https://user-images.githubusercontent.com/63644587/117575087-46809f80-b11b-11eb-9d31-5f6744da4a87.png)

    - x축은 연산의 횟수를 의미하며, y축은 그러한 횟수의 빈도를 의미한다.
    - 두 방식의 분포를 살펴보면 위와 같이 연산의 횟수가 커질수록 빈도가 줄어들고 있음을 보여준다. 이는 기존의 데이터의 정렬 정도에 기반하여 대부분의 경우 마지막 노드까지 순회하기보다 중간에 자신의 위치를 찾는 경우가 많음을 의미한다.
    - 기존 알고리즘의 경우 연산 횟수가 데이터의 갯수까지 분포하고 있음을 확인할 수 있다.
    - 그러나 개선 알고리즘의 경우 동일한 데이터를 처리했지만 약 5천번까지 분포하고 있으며, 적은 연산횟수의 빈도가 잦은 한편, 기존 알고리즘에 비해 큰 연산횟수의 빈도가 급격히 줄어드는 것을 확인할 수 있다. 

- 통계
  - 개별 단어를 추가하는데 소요되는 연산의 횟수를 통계적인 수치로 나타내면 다음과 같다. 최솟값은 0으로 동일하다.


    ||**최댓값**|**평균값**|**중위값**|**표준편차**|
    | - | - | - | - | - |
    |**개선 전**|48043|12112|9021|10686|
    |**개선 후**|5490|736|462|808|

    - 최대 연산 횟수는 개선 전의 경우 전체 데이터에 근사하게 나타나는 반면, 개선 후에는 하나의 데이터를 추가할 때 드는 연산의 횟수의 최댓값이 전체 데이터의 11%에 불과함을 확인할 수 있다.
    - 개선 전의 평균값과 중위값 모두 개선 후보다 상당히 크므로 개선 전의 최댓값에 의한 평균의 왜곡으로 알고리즘의 효율성 평가가 왜곡되지 않음을 확인할 수 있다.
    - 표준편차를 살펴보았을 때 연산 횟수의 분포가 개선 전의 경우 매우 넓고 불안정하게 되어있는 반면, 개선 후 연산 횟수의 분포가 상대적으로 안정적이다.
